name: Daily NSE Option Analysis

on:
  schedule:
    - cron: '30 8 * * 1-5'  # Runs at 2:00 PM IST (8:30 UTC) on weekdays
  workflow_dispatch:         # Manual trigger

jobs:
  run-analysis:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy requests
    
    - name: Create directories
      run: |
        mkdir -p data/raw
        mkdir -p data/processed
        mkdir -p outputs/signals
        mkdir -p outputs/reports
        echo "Directories created successfully"
    
    - name: Download previous historical data
      uses: actions/download-artifact@v4
      if: always()
      with:
        name: nse-historical-data
        path: data/processed/
        continue-on-error: true
    
    - name: Check downloaded historical data
      run: |
        echo "=== Checking downloaded historical data ==="
        if [ -d "data/processed" ]; then
          echo "✅ Processed data directory exists"
          echo ""
          echo "=== Files in data/processed ==="
          ls -la data/processed/
          echo ""
          echo "=== CSV files found ==="
          find data/processed -name "*.csv" -type f | sort
          echo ""
          echo "=== File details ==="
          for csv_file in $(find data/processed -name "*.csv" -type f | sort); do
            echo "File: $(basename $csv_file)"
            echo "  Size: $(wc -l < "$csv_file") lines"
            echo "  Date in filename: $(basename $csv_file | sed 's/nse_fo_//;s/.csv//')"
            if [ -f "$csv_file" ]; then
              # Check first few lines for date
              echo "  First line: $(head -1 "$csv_file" | cut -c1-50)..."
            fi
            echo ""
          done
        else
          echo "❌ No processed data directory found"
        fi
    
    - name: Run analysis
      run: python run.py
    
    - name: Upload new historical data
      uses: actions/upload-artifact@v4
      with:
        name: nse-historical-data
        path: data/processed/
        retention-days: 90
        if-no-files-found: warn
    
    - name: List generated files
      run: |
        echo "=== Generated Reports ==="
        find outputs/ -type f -name "*.txt" -o -name "*.csv" | sort || echo "No reports found"
        echo ""
        echo "=== Current Historical Data ==="
        find data/processed -name "*.csv" -type f | sort || echo "No historical data files"
        echo ""
        echo "=== Artifact Status ==="
        echo "Historical data will be available for next run"
    
    - name: Commit and push results
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add outputs/
        git status
        git diff --cached --quiet || (git commit -m "Update NSE analysis reports $(date +'%Y-%m-%d %H:%M:%S')" && git push)
        echo "✅ Reports committed to repository"
